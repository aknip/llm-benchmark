{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlqx6I08bMZbrLBu+GTYTi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aknip/llm-benchmark/blob/main/llm_simple_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O1ck0sc0m2v"
      },
      "outputs": [],
      "source": [
        "!pip install openai litellm pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from getpass import getpass\n",
        "import psutil\n",
        "import requests\n",
        "IN_NOTEBOOK = any([\"jupyter-notebook\" in i for i in psutil.Process().parent().cmdline()])\n",
        "if IN_NOTEBOOK:\n",
        "  CREDS = json.loads(getpass(\"Secrets (JSON string): \"))\n",
        "  os.environ['CREDS'] = json.dumps(CREDS)\n",
        "  CREDS = json.loads(os.getenv('CREDS'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myZYsW9oZkEv",
        "outputId": "6e295ed5-039c-43fa-e3cd-7d9179cfc79c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Secrets (JSON string): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = CREDS['OpenAI']['v1']['credential'] # my key\n",
        "os.environ[\"TOGETHERAI_API_KEY\"] = CREDS['together-ai']['key']['credential']"
      ],
      "metadata": {
        "id": "y0pi_2z0ZsOS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call via OpenAI"
      ],
      "metadata": {
        "id": "EvXqmtEFcxXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "client = openai.OpenAI(\n",
        "  api_key=os.environ.get(\"TOGETHERAI_API_KEY\"),\n",
        "  base_url='https://api.together.xyz',\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Tell me about San Francisco\",\n",
        "    }\n",
        "  ],\n",
        "  model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "  max_tokens=1024\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku-bklBeaTpI",
        "outputId": "812d708c-7553-4b9f-b09f-220b17fa6190"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "San Francisco is a vibrant and culturally diverse city located in northern California, USA. It is known for its steep rolling hills, iconic landmarks, and cool, foggy weather. Here are some key facts and points of interest about San Francisco:\n",
            "\n",
            "1. History: San Francisco was founded in 1776 by Spanish colonists and was originally a small mission and military outpost. It grew rapidly during the California Gold Rush in the mid-1800s and became a major commercial and cultural center.\n",
            "2. Geography: San Francisco is situated on the tip of a peninsula, surrounded by the San Francisco Bay and the Pacific Ocean. It covers an area of about 47 square miles and has a population of approximately 875,000 people.\n",
            "3. Landmarks: San Francisco is home to many iconic landmarks, including the Golden Gate Bridge, Alcatraz Island, Fisherman's Wharf, Lombard Street, and Chinatown.\n",
            "4. Culture: San Francisco is known for its vibrant cultural scene, with world-class museums, theaters, and music venues. It is also home to a thriving LGBTQ+ community and is famous for its annual Pride Parade.\n",
            "5. Technology: San Francisco is a major hub for the technology industry, with many tech companies, including Twitter, Uber, and Salesforce, headquartered in the city.\n",
            "6. Education: San Francisco has a highly educated population, with over 50% of residents holding a bachelor's degree or higher. It is home to several prestigious universities, including the University of California, San Francisco (UCSF), and San Francisco State University.\n",
            "7. Climate: San Francisco has a mild, Mediterranean climate, with cool, foggy summers and mild, wet winters. The city is known for its microclimates, with different neighborhoods experiencing different weather patterns.\n",
            "8. Transportation: San Francisco has a comprehensive public transportation system, including buses, light rail, and the iconic cable cars. The city is also served by the Bay Area Rapid Transit (BART) system, which connects San Francisco to the surrounding Bay Area.\n",
            "9. Sports: San Francisco is home to several professional sports teams, including the San Francisco Giants (baseball), the San Francisco 49ers (football), and the Golden State Warriors (basketball).\n",
            "10. Food: San Francisco is known for its diverse and innovative food scene, with a wide range of cuisines and dining options, from fine dining to street food. The city is famous for its seafood, sourdough bread, and farm-to-table restaurants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call via litellm"
      ],
      "metadata": {
        "id": "E_gDWvF6c1jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4QNQHwhc38u",
        "outputId": "70ae6eb1-74cf-47c0-f257-37df85ce25c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm an AI language model, so I don't have feelings, but I'm here to help and answer any questions you may have. How can I assist you today?\n",
            "ModelResponse(id='chatcmpl-8aJq4ZzYqZx9RpZZISWALpdBwgCX0', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello! I'm an AI language model, so I don't have feelings, but I'm here to help and answer any questions you may have. How can I assist you today?\", role='assistant'))], created=1703666759, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=37, prompt_tokens=13, total_tokens=50), _response_ms=2601.7450000000003)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = completion(\n",
        "  #model=\"together_ai/togethercomputer/Llama-2-7B-32K-Instruct\",\n",
        "  model=\"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
        ")\n",
        "print(response.choices[0].message.content)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoaFpFXKc8zE",
        "outputId": "259ae261-2bb5-4400-8624-ac9b6551296c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you with any questions you have. Is there something specific you would like to know or talk about?\n",
            "ModelResponse(id='chatcmpl-060eab6b-3cfb-45dd-ad25-9a2ff02dfbfe', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you with any questions you have. Is there something specific you would like to know or talk about?\", role='assistant'))], created=1703667116, model='mistralai/Mixtral-8x7B-Instruct-v0.1', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=12, completion_tokens=44, total_tokens=56), _response_ms=2404.737)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Calling"
      ],
      "metadata": {
        "id": "XJyLwl3CjYOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://litellm.vercel.app/docs/completion/function_call\n",
        "\n",
        "# via Huggingface?\n",
        "# https://litellm.vercel.app/docs/providers/huggingface\n",
        "# https://huggingface.co/Trelis/Mixtral-8x7B-Instruct-v0.1-function-calling-v3\n",
        "# https://huggingface.co/Trelis/Mistral-7B-Instruct-v0.1-function-calling-v2\n",
        "\n",
        "# via Anyscale?\n",
        "# https://docs.litellm.ai/docs/providers/anyscale\n",
        "# https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features"
      ],
      "metadata": {
        "id": "lD6O-SQxjbCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, litellm\n",
        "from litellm import completion\n",
        "\n",
        "# IMPORTANT - Set this to TRUE to add the function to the prompt for Non OpenAI LLMs\n",
        "litellm.add_function_to_prompt = True\n",
        "\n",
        "# The real function is not needed for the LLM. It may be called after the LLM call (not in this code!)\n",
        "def get_current_weather(location):\n",
        "  if location == \"Boston, MA\":\n",
        "    return \"The weather is 12F\"\n",
        "\n",
        "functions = [\n",
        "    {\n",
        "      \"name\": \"get_current_weather\",\n",
        "      \"description\": \"Get the current weather in a given location\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"location\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
        "          },\n",
        "          \"unit\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"location\"]\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is the weather like in Boston?\"}\n",
        "]\n",
        "\n",
        "response = completion(model=\"gpt-3.5-turbo-1106\", messages=messages, functions=functions)\n",
        "\n",
        "print(response)\n",
        "print()\n",
        "function_found = hasattr(response.choices[0]['message'], 'function_call')\n",
        "if function_found == True:\n",
        "  function_call = response.choices[0]['message']['function_call']\n",
        "  function_call_name = function_call.name\n",
        "  function_call_arguments = function_call.arguments\n",
        "  print(function_call_name)\n",
        "else:\n",
        "  print('No function found')"
      ],
      "metadata": {
        "id": "TG6qj6W282Dz",
        "outputId": "d103dcc3-6874-438e-cbb9-6e49efc10f2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModelResponse(id='chatcmpl-8aMIy9IwTKgIGAHBt8w8kku1aR6Jw', choices=[Choices(finish_reason='function_call', index=0, message=Message(content=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\"}', name='get_current_weather')))], created=1703676240, model='gpt-3.5-turbo-1106', object='chat.completion', system_fingerprint='fp_772e8125bb', usage=Usage(completion_tokens=17, prompt_tokens=82, total_tokens=99), _response_ms=1680.471)\n",
            "\n",
            "get_current_weather\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create Excel file"
      ],
      "metadata": {
        "id": "qMx9SDXex-CK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "# see https://openpyxl.readthedocs.io/en/2.4/pandas.html\n",
        "\n",
        "# Create a Pandas dataframe from the data.\n",
        "df = pd.DataFrame({'Name': ['Miller', 'Adams', 'Smith'],\n",
        "                   'Prompt': ['Write something', 'Do different things', 'Summarize it'], })\n",
        "\n",
        "# Create a Pandas Excel writer using openpyxl as the engine.\n",
        "writer = pd.ExcelWriter('llm_benchmark.xlsx', engine='openpyxl')\n",
        "\n",
        "# Convert the dataframe to an XlsxWriter Excel object.\n",
        "df.to_excel(writer, sheet_name='Benchmark', index=True)\n",
        "\n",
        "# Get the xlsxwriter objects from the dataframe writer object.\n",
        "workbook  = writer.book\n",
        "worksheet = writer.sheets['Benchmark']\n",
        "\n",
        "# Save the Excel file.\n",
        "workbook.save('llm_benchmark.xlsx')\n",
        "\n",
        "# Alternate approach without ExcelWriter:\n",
        "# workbook = Workbook()\n",
        "# worksheet = workbook.active\n",
        "# for row in dataframe_to_rows(df, index=True, header=True):\n",
        "#     if row != [None]:\n",
        "#       worksheet.append(row)"
      ],
      "metadata": {
        "id": "fRhw6GLCxQLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Read Excel file as dataframe"
      ],
      "metadata": {
        "id": "aPYRadlYz2v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#import xlrd\n",
        "\n",
        "df = pd.read_excel('llm_benchmark.xlsx', sheet_name='Benchmark') # parse_dates=['date'] # dtype={'column_name': float}\n",
        "#print(df.head())\n",
        "\n",
        "print(\"Given Dataframe :\\n\", df)\n",
        "\n",
        "print(\"\\nIterating 1:\")\n",
        "for i in df.index:\n",
        "    print(i, df['Name'][i],df['Prompt'][i])\n",
        "\n",
        "print(\"\\nIterating 2:\")\n",
        "for index, row in df.iterrows():\n",
        "    name = row['Name']\n",
        "    prompt = row['Prompt']\n",
        "    print(f\"{index}: {name}, {prompt}\")"
      ],
      "metadata": {
        "id": "eQ-GM5MqzMwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Updata data and Excel file"
      ],
      "metadata": {
        "id": "jnRHMJPx16hM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.at[1, 'Name'] = 'Name-Updated'\n",
        "df.at[2, 'Prompt'] = 'Prompt-Updated'\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "c7kIjqA22Oy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl import Workbook\n",
        "from openpyxl import load_workbook\n",
        "workbook = load_workbook(filename = 'llm_benchmark.xlsx')\n",
        "worksheet = workbook.active\n",
        "\n",
        "print(\"Updating Excel file:\")\n",
        "for index, row in df.iterrows():\n",
        "    name = row['Name']\n",
        "    prompt = row['Prompt']\n",
        "    print(f\"{index}: {name}, {prompt}\")\n",
        "    d = worksheet.cell(row=index+2, column=2, value=name)\n",
        "    d = worksheet.cell(row=index+2, column=3, value=prompt)\n",
        "\n",
        "# Alternative: delete data rows and append dataframe to worksheet\n",
        "# continuously delete row 2 until there is only first row (header row) is left over\n",
        "# while(worksheet.max_row > 1):\n",
        "#     worksheet.delete_rows(2) # removes the row 2\n",
        "# append dataframe to worksheet\n",
        "# for row in dataframe_to_rows(df, index=False, header=False):\n",
        "#     if row != [None]:\n",
        "#        worksheet.append(row)\n",
        "\n",
        "# Save the Excel file.\n",
        "workbook.save('llm_benchmark.xlsx')"
      ],
      "metadata": {
        "id": "SCUeSs4N2nQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}